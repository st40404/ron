
1.install webcam driver
    git clone https://github.com/ros-drivers/usb_cam.git

2.test your cam
    roslaunch usb_cam usb_cam-test.launch

3.update rosdep
    rosdep update

3.install calibration dependencies
    rosdep install camera_calibration

4.try to use calibration
    rosrun camera_calibration cameracalibrator.py --size 8x6 --square 0.108 image:=/usb_cam/image_raw camera:=/usb_cam
    (suggess: upload your default python version to 2.7)
    (calibration board: http://wiki.ros.org/camera_calibration/Tutorials/MonocularCalibration?action=AttachFile&do=view&target=check-108.pdf)
    
5.add parameter in your launch file of usb_cam, add in "camera" node 
    <param name="camera_info_url" value="file:///home/ron/ORBSLAM2/src/calibrationdata/ost.yaml" />

6.download orb_slam2    
    git clone https://github.com/appliedAI-Initiative/orb_slam_2_ros.git

7.create launch file name as orb_slam2_mono_new.launch
    <launch>
    <node name="orb_slam2_mono" pkg="orb_slam2_ros"
        type="orb_slam2_ros_mono" output="screen">
    <param name="publish_pointcloud" type="bool" value="true" />
        <param name="publish_pose" type="bool" value="true" />
        <param name="localize_only" type="bool" value="false" />
        <param name="reset_map" type="bool" value="true" />
    <!-- static parameters -->
        <param name="load_map" type="bool" value="false" />
        <param name="map_file" type="string" value="map.bin" />
        <param name="voc_file" type="string" value="$(find orb_slam2_ros)/orb_slam2/Vocabulary/ORBvoc.txt" />
    <param name="pointcloud_frame_id" type="string" value="map" />
        <param name="camera_frame_id" type="string" value="camera_link" />
        <param name="min_num_kf_in_map" type="int" value="5" />
    <!-- ORB parameters -->
        <param name="/ORBextractor/nFeatures" type="int" value="2000" />
        <param name="/ORBextractor/scaleFactor" type="double" value="1.2" />
        <param name="/ORBextractor/nLevels" type="int" value="8" />
        <param name="/ORBextractor/iniThFAST" type="int" value="20" />
        <param name="/ORBextractor/minThFAST" type="int" value="7" />
    <!-- Camera parameters -->
        <!-- Camera frames per second -->
        <param name="camera_fps" type="int" value="30" />
        <!-- Color order of the images (0: BGR, 1: RGB. It is ignored if images are grayscale) -->
        <param name="camera_rgb_encoding" type="bool" value="true" />
            <!--If the node should wait for a camera_info topic to take the camera calibration data-->
        <param name="load_calibration_from_cam" type="bool" value="true" />
    </node>
    </launch>

8.create a node in "script" folder as camera.py
    #!/usr/bin/env python
    import rospy
    import cv2
    from cv_bridge import CvBridge
    from sensor_msgs.msg import Image
    bridge = CvBridge()
    def callback(data):
        frame = bridge.imgmsg_to_cv2(data, "bgr8")
        cv2.imshow('Video Feed', frame)
        cv2.waitKey(1)
        rospy.loginfo('Image feed received!')
    def listener():
        rospy.init_node('vid_rec')
        #first parameter is the topic you want to subcribe sensor_msgs/Image from
        rospy.Subscriber('/orb_slam2_mono/debug_image', Image, callback)
        rospy.spin()
    if __name__ == '__main__':
        listener()

9.make your node excutable 
    chmod +x camera.py

10.change to pkg name from camera to usb_cam in ros/src/Mononode.cc file
    change /camera/camera_info   to   /usb_cam/camera_info
    change /camera/image_raw     to   /usb_cam/image_raw

11.excute each node and check
    roslaunch usb_cam usb_cam-test.launch
    roslaunch orb_slam2_ros orb_slam2_mono_new.launch
    rosrun orb_slam2_ros camera.py 
    rosrun rviz rviz

12.change the "camera_link" in orb_slam2_mono_new.launch to "base_link"

